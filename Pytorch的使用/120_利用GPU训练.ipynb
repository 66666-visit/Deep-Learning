{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 利用GPU训练(方式一)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① GPU训练主要有三部分，网络模型、数据(输入、标注)、损失函数，这三部分放到GPU上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集的长度：50000\n",
      "测试数据集的长度：10000\n",
      "-----第 1 轮训练开始-----\n",
      "训练次数：100,Loss:2.2835426330566406\n",
      "训练次数：200,Loss:2.285886526107788\n",
      "训练次数：300,Loss:2.259626865386963\n",
      "训练次数：400,Loss:2.180846691131592\n",
      "训练次数：500,Loss:2.092060089111328\n",
      "训练次数：600,Loss:2.040146589279175\n",
      "训练次数：700,Loss:2.0112416744232178\n",
      "整体测试集上的Loss:312.11917674541473\n",
      "整体测试集上的正确率:0.2897000014781952\n",
      "模型已保存\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),  # 输入通道3，输出通道32，卷积核尺寸5×5，步长1，填充2    \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # 展平后变成 64*4*4 了\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(r'D:\\深度学习\\100_土堆数据集\\dataset', train=True, transform=torchvision.transforms.ToTensor())       \n",
    "# train=False: 下载并加载测试集 (10000张)\n",
    "test_data = torchvision.datasets.CIFAR10(r'D:\\深度学习\\100_土堆数据集\\dataset', train=False, transform=torchvision.transforms.ToTensor())       \n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10，则打印：训练数据集的长度为：10\n",
    "print(\"训练数据集的长度：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度：{}\".format(test_data_size))\n",
    "\n",
    "# 利用 Dataloader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)        \n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "tudui = Tudui() \n",
    "\n",
    "tudui = tudui.to(device)\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵，fn 是 fuction 的缩写\n",
    "loss_fn = loss_fn.to(device)       # 损失函数转移到cuda上\n",
    "\n",
    "# 优化器\n",
    "learning = 0.01  # 1e-2 就是 0.01 的意思\n",
    "optimizer = torch.optim.SGD(tudui.parameters(),learning)   # 随机梯度下降优化器  \n",
    "\n",
    "# 设置网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "\n",
    "# 训练的轮次\n",
    "epoch = 1\n",
    "\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----第 {} 轮训练开始-----\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    tudui.train() # 当网络中有dropout层、batchnorm层时，这些层能起作用\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = tudui(imgs)\n",
    "        loss = loss_fn(outputs, targets) # 计算实际输出与目标输出的差距\n",
    "        \n",
    "        # 优化器对模型调优\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward() # 反向传播，计算损失函数的梯度\n",
    "        optimizer.step()   # 根据梯度，对网络的参数进行调优\n",
    "        \n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{},Loss:{}\".format(total_train_step,loss.item()))  # 方式二：获得loss值\n",
    "           \n",
    "    \n",
    "    # 测试步骤开始（每一轮训练后都查看在测试数据集上的loss情况）\n",
    "    tudui.eval()  # 当网络中有dropout层、batchnorm层时，这些层不能起作用\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():  # 没有梯度了\n",
    "        for data in test_dataloader: # 测试数据集提取数据\n",
    "            imgs, targets = data # 数据放到cuda上\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = tudui(imgs)\n",
    "            loss = loss_fn(outputs, targets) # 仅data数据在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss.item() # 所有loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "            \n",
    "    print(\"整体测试集上的Loss:{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率:{}\".format(total_accuracy/test_data_size))\n",
    "    total_test_step = total_test_step + 1\n",
    "    \n",
    "    torch.save(tudui, f\"D:\\\\深度学习\\\\Pytorch的使用\\\\model\\\\tudui_{i}.pth\") # 保存每一轮训练后的结果\n",
    "    #torch.save(tudui.state_dict(),\"tudui_{}.path\".format(i)) # 保存方式二         \n",
    "    print(\"模型已保存\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. GPU训练时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集的长度：50000\n",
      "测试数据集的长度：10000\n",
      "-----第 1 轮训练开始-----\n",
      "0.9865736961364746\n",
      "训练次数：100，Loss：2.287412166595459\n",
      "1.826425313949585\n",
      "训练次数：200，Loss：2.2787041664123535\n",
      "2.603532552719116\n",
      "训练次数：300，Loss：2.2505364418029785\n",
      "3.3888461589813232\n",
      "训练次数：400，Loss：2.2002716064453125\n",
      "4.031994581222534\n",
      "训练次数：500，Loss：2.1392476558685303\n",
      "4.722864627838135\n",
      "训练次数：600，Loss：2.0769171714782715\n",
      "5.430900573730469\n",
      "训练次数：700，Loss：1.9968907833099365\n",
      "整体测试集上的Loss：311.3536899089813\n",
      "整体测试集上的正确率：0.3010999858379364\n",
      "模型已保存\n",
      "-----第 2 轮训练开始-----\n",
      "7.367185354232788\n",
      "训练次数：800，Loss：1.8529436588287354\n",
      "8.024590969085693\n",
      "训练次数：900，Loss：1.8158364295959473\n",
      "8.747882843017578\n",
      "训练次数：1000，Loss：1.9458039999008179\n",
      "9.467170000076294\n",
      "训练次数：1100，Loss：2.041217803955078\n",
      "10.22244143486023\n",
      "训练次数：1200，Loss：1.6707229614257812\n",
      "11.028911828994751\n",
      "训练次数：1300，Loss：1.6479181051254272\n",
      "11.732660293579102\n",
      "训练次数：1400，Loss：1.7263314723968506\n",
      "12.405974864959717\n",
      "训练次数：1500，Loss：1.7926069498062134\n",
      "整体测试集上的Loss：302.337841629982\n",
      "整体测试集上的正确率：0.31540000438690186\n",
      "模型已保存\n",
      "-----第 3 轮训练开始-----\n",
      "14.10306715965271\n",
      "训练次数：1600，Loss：1.7203154563903809\n",
      "14.886370182037354\n",
      "训练次数：1700，Loss：1.6618690490722656\n",
      "15.599971055984497\n",
      "训练次数：1800，Loss：1.9473438262939453\n",
      "16.254693746566772\n",
      "训练次数：1900，Loss：1.717003583908081\n",
      "16.938133716583252\n",
      "训练次数：2000，Loss：1.9232995510101318\n",
      "17.664772510528564\n",
      "训练次数：2100，Loss：1.5160430669784546\n",
      "18.419418573379517\n",
      "训练次数：2200，Loss：1.4515472650527954\n",
      "19.083365440368652\n",
      "训练次数：2300，Loss：1.7984824180603027\n",
      "整体测试集上的Loss：264.75967597961426\n",
      "整体测试集上的正确率：0.3958999812602997\n",
      "模型已保存\n",
      "-----第 4 轮训练开始-----\n",
      "20.64089012145996\n",
      "训练次数：2400，Loss：1.6928980350494385\n",
      "21.30539560317993\n",
      "训练次数：2500，Loss：1.3598887920379639\n",
      "21.96066975593567\n",
      "训练次数：2600，Loss：1.5937132835388184\n",
      "22.621057748794556\n",
      "训练次数：2700，Loss：1.7072808742523193\n",
      "23.29099726676941\n",
      "训练次数：2800，Loss：1.4710934162139893\n",
      "23.91313076019287\n",
      "训练次数：2900，Loss：1.621895670890808\n",
      "24.541380167007446\n",
      "训练次数：3000，Loss：1.3436777591705322\n",
      "25.178183555603027\n",
      "训练次数：3100，Loss：1.5145281553268433\n",
      "整体测试集上的Loss：253.01317071914673\n",
      "整体测试集上的正确率：0.4172999858856201\n",
      "模型已保存\n",
      "-----第 5 轮训练开始-----\n",
      "26.78757357597351\n",
      "训练次数：3200，Loss：1.3523101806640625\n",
      "27.458211660385132\n",
      "训练次数：3300，Loss：1.4745275974273682\n",
      "28.089956045150757\n",
      "训练次数：3400，Loss：1.4859960079193115\n",
      "28.721973657608032\n",
      "训练次数：3500，Loss：1.5437219142913818\n",
      "29.359358549118042\n",
      "训练次数：3600，Loss：1.5800459384918213\n",
      "30.019887447357178\n",
      "训练次数：3700，Loss：1.3482989072799683\n",
      "30.685250282287598\n",
      "训练次数：3800，Loss：1.283921718597412\n",
      "31.36015796661377\n",
      "训练次数：3900，Loss：1.441655158996582\n",
      "整体测试集上的Loss：251.68911218643188\n",
      "整体测试集上的正确率：0.42080000042915344\n",
      "模型已保存\n",
      "-----第 6 轮训练开始-----\n",
      "32.9152946472168\n",
      "训练次数：4000，Loss：1.4169195890426636\n",
      "33.574182748794556\n",
      "训练次数：4100，Loss：1.4368603229522705\n",
      "34.22669768333435\n",
      "训练次数：4200，Loss：1.5082931518554688\n",
      "34.884575843811035\n",
      "训练次数：4300，Loss：1.2204080820083618\n",
      "35.53759694099426\n",
      "训练次数：4400，Loss：1.1661934852600098\n",
      "36.165910482406616\n",
      "训练次数：4500，Loss：1.3913733959197998\n",
      "36.80575919151306\n",
      "训练次数：4600，Loss：1.4178578853607178\n",
      "整体测试集上的Loss：243.7917274236679\n",
      "整体测试集上的正确率：0.4412999749183655\n",
      "模型已保存\n",
      "-----第 7 轮训练开始-----\n",
      "38.4068865776062\n",
      "训练次数：4700，Loss：1.3640029430389404\n",
      "39.084957122802734\n",
      "训练次数：4800，Loss：1.553741693496704\n",
      "39.729716062545776\n",
      "训练次数：4900，Loss：1.4104011058807373\n",
      "40.35842514038086\n",
      "训练次数：5000，Loss：1.3906265497207642\n",
      "40.99583888053894\n",
      "训练次数：5100，Loss：0.9967275857925415\n",
      "41.64541959762573\n",
      "训练次数：5200，Loss：1.303032636642456\n",
      "42.303555488586426\n",
      "训练次数：5300，Loss：1.187888503074646\n",
      "42.97315812110901\n",
      "训练次数：5400，Loss：1.3841391801834106\n",
      "整体测试集上的Loss：230.46902894973755\n",
      "整体测试集上的正确率：0.47200000286102295\n",
      "模型已保存\n",
      "-----第 8 轮训练开始-----\n",
      "44.55383586883545\n",
      "训练次数：5500，Loss：1.2183014154434204\n",
      "45.216039180755615\n",
      "训练次数：5600，Loss：1.157867670059204\n",
      "45.86014986038208\n",
      "训练次数：5700，Loss：1.1492819786071777\n",
      "46.525141954422\n",
      "训练次数：5800，Loss：1.2730891704559326\n",
      "47.2290141582489\n",
      "训练次数：5900，Loss：1.3939993381500244\n",
      "47.97516322135925\n",
      "训练次数：6000，Loss：1.516404628753662\n",
      "48.87245416641235\n",
      "训练次数：6100，Loss：1.0970972776412964\n",
      "49.60933184623718\n",
      "训练次数：6200，Loss：1.1081242561340332\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 100\u001b[0m\n\u001b[0;32m     98\u001b[0m total_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# 没有梯度了\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m test_dataloader: \u001b[38;5;66;03m# 测试数据集提取数据\u001b[39;00m\n\u001b[0;32m    101\u001b[0m         imgs, targets \u001b[38;5;241m=\u001b[39m data \u001b[38;5;66;03m# 数据放到cuda上\u001b[39;00m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui, self).__init__()        \n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),  # 输入通道3，输出通道32，卷积核尺寸5×5，步长1，填充2    \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # 展平后变成 64*4*4 了\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "# 准备数据集\n",
    " # 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(r'D:\\深度学习\\100_土堆数据集\\dataset', train=True, transform=torchvision.transforms.ToTensor())       \n",
    "# train=False: 下载并加载测试集 (10000张)\n",
    "test_data = torchvision.datasets.CIFAR10(r'D:\\深度学习\\100_土堆数据集\\dataset', train=False, transform=torchvision.transforms.ToTensor()) \n",
    "  \n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10，则打印：训练数据集的长度为：10\n",
    "print(\"训练数据集的长度：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度：{}\".format(test_data_size))\n",
    "\n",
    "# 利用 Dataloader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)        \n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "tudui = Tudui() \n",
    "if torch.cuda.is_available():\n",
    "    tudui = tudui.cuda() # 网络模型转移到cuda上\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵，fn 是 fuction 的缩写\n",
    "if torch.cuda.is_available():\n",
    "    loss_fn = loss_fn.cuda()        # 损失函数转移到cuda上\n",
    "\n",
    "# 优化器\n",
    "learning = 0.01  # 1e-2 就是 0.01 的意思\n",
    "optimizer = torch.optim.SGD(tudui.parameters(),learning)   # 随机梯度下降优化器  \n",
    "\n",
    "# 设置网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "\n",
    "# 训练的轮次\n",
    "epoch = 10\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----第 {} 轮训练开始-----\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    tudui.train() # 当网络中有dropout层、batchnorm层时，这些层能起作用\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()  # 数据放到cuda上\n",
    "            targets = targets.cuda() # 数据放到cuda上\n",
    "        outputs = tudui(imgs)\n",
    "        loss = loss_fn(outputs, targets) # 计算实际输出与目标输出的差距\n",
    "        \n",
    "        # 优化器对模型调优\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward() # 反向传播，计算损失函数的梯度\n",
    "        optimizer.step()   # 根据梯度，对网络的参数进行调优\n",
    "        \n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(end_time - start_time) # 运行训练一百次后的时间间隔\n",
    "            print(\"训练次数：{}，Loss：{}\".format(total_train_step,loss.item()))  # 方式二：获得loss值\n",
    "    \n",
    "    # 测试步骤开始（每一轮训练后都查看在测试数据集上的loss情况）\n",
    "    tudui.eval()  # 当网络中有dropout层、batchnorm层时，这些层不能起作用\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():  # 没有梯度了\n",
    "        for data in test_dataloader: # 测试数据集提取数据\n",
    "            imgs, targets = data # 数据放到cuda上\n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda() # 数据放到cuda上\n",
    "                targets = targets.cuda()\n",
    "            outputs = tudui(imgs)\n",
    "            loss = loss_fn(outputs, targets) # 仅data数据在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss.item() # 所有loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "            \n",
    "    print(\"整体测试集上的Loss：{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(total_accuracy/test_data_size))\n",
    "    total_test_step = total_test_step + 1\n",
    "    \n",
    "    torch.save(tudui, f\"D:\\\\深度学习\\\\Pytorch的使用\\\\model\\\\tudui_{i}.pth\") # 保存每一轮训练后的结果\n",
    "    #torch.save(tudui.state_dict(),\"tudui_{}.path\".format(i)) # 保存方式二         \n",
    "    print(\"模型已保存\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CPU训练时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集的长度：50000\n",
      "测试数据集的长度：10000\n",
      "-----第 1 轮训练开始-----\n",
      "2.529812812805176\n",
      "训练次数：100，Loss：2.285748243331909\n",
      "4.923457860946655\n",
      "训练次数：200，Loss：2.2780470848083496\n",
      "7.414954662322998\n",
      "训练次数：300，Loss：2.2396554946899414\n",
      "9.708266496658325\n",
      "训练次数：400，Loss：2.15100359916687\n",
      "12.14492654800415\n",
      "训练次数：500，Loss：2.069103717803955\n",
      "14.379271268844604\n",
      "训练次数：600，Loss：2.0509653091430664\n",
      "16.635051488876343\n",
      "训练次数：700，Loss：1.976069688796997\n",
      "整体测试集上的Loss:307.152171254158\n",
      "整体测试集上的正确率：0.2930000126361847\n",
      "模型已保存\n",
      "-----第 2 轮训练开始-----\n",
      "21.181365966796875\n",
      "训练次数：800，Loss：1.832400918006897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# 训练步骤开始\u001b[39;00m\n\u001b[0;32m     69\u001b[0m tudui\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# 当网络中有dropout层、batchnorm层时，这些层能起作用\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m     71\u001b[0m     imgs, targets \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     72\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m tudui(imgs)\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui, self).__init__()        \n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),  # 输入通道3，输出通道32，卷积核尺寸5×5，步长1，填充2    \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # 展平后变成 64*4*4 了\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(r'D:\\深度学习\\100_土堆数据集\\dataset', train=True, transform=torchvision.transforms.ToTensor())       \n",
    "# train=False: 下载并加载测试集 (10000张)\n",
    "test_data = torchvision.datasets.CIFAR10(r'D:\\深度学习\\100_土堆数据集\\dataset', train=False, transform=torchvision.transforms.ToTensor()) \n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10，则打印：训练数据集的长度为：10\n",
    "print(\"训练数据集的长度：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度：{}\".format(test_data_size))\n",
    "\n",
    "# 利用 Dataloader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)        \n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "tudui = Tudui() \n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵，fn 是 fuction 的缩写\n",
    "\n",
    "# 优化器\n",
    "learning = 0.01  # 1e-2 就是 0.01 的意思\n",
    "optimizer = torch.optim.SGD(tudui.parameters(),learning)   # 随机梯度下降优化器  \n",
    "\n",
    "# 设置网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "\n",
    "# 训练的轮次\n",
    "epoch = 10\n",
    "\n",
    "# 添加 tensorboard\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----第 {} 轮训练开始-----\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    tudui.train() # 当网络中有dropout层、batchnorm层时，这些层能起作用\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = tudui(imgs)\n",
    "        loss = loss_fn(outputs, targets) # 计算实际输出与目标输出的差距\n",
    "        \n",
    "        # 优化器对模型调优\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward() # 反向传播，计算损失函数的梯度\n",
    "        optimizer.step()   # 根据梯度，对网络的参数进行调优\n",
    "        \n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(end_time - start_time) # 运行训练一百次后的时间间隔\n",
    "            print(\"训练次数：{}，Loss：{}\".format(total_train_step,loss.item()))  # 方式二：获得loss值\n",
    "\n",
    "    # 测试步骤开始（每一轮训练后都查看在测试数据集上的loss情况）\n",
    "    tudui.eval()  # 当网络中有dropout层、batchnorm层时，这些层不能起作用\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():  # 没有梯度了\n",
    "        for data in test_dataloader: # 测试数据集提取数据\n",
    "            imgs, targets = data \n",
    "            outputs = tudui(imgs)\n",
    "            loss = loss_fn(outputs, targets) # 仅data数据在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss.item() # 所有loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "            \n",
    "    print(\"整体测试集上的Loss:{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(total_accuracy/test_data_size))\n",
    "    total_test_step = total_test_step + 1\n",
    "    \n",
    "    torch.save(tudui, f\"D:\\\\深度学习\\\\Pytorch的使用\\\\model\\\\tudui_{i}.pth\") # 保存每一轮训练后的结果\n",
    "    #torch.save(tudui.state_dict(),\"tudui_{}.path\".format(i)) # 保存方式二         \n",
    "    print(\"模型已保存\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 利用GPU训练(方式二)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 电脑上有两个显卡时，可以用指定cuda:0、cuda:1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集的长度：50000\n",
      "测试数据集的长度：10000\n",
      "-----第 1 轮训练开始-----\n",
      "0.8625242710113525\n",
      "训练次数：100,Loss:2.2969915866851807\n",
      "1.6750540733337402\n",
      "训练次数：200,Loss:2.2790942192077637\n",
      "2.476668119430542\n",
      "训练次数：300,Loss:2.252523183822632\n",
      "3.181696653366089\n",
      "训练次数：400,Loss:2.1528258323669434\n",
      "3.9274096488952637\n",
      "训练次数：500,Loss:2.0328617095947266\n",
      "4.731224298477173\n",
      "训练次数：600,Loss:1.997795581817627\n",
      "5.584262371063232\n",
      "训练次数：700,Loss:2.0016860961914062\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 102\u001b[0m\n\u001b[0;32m    100\u001b[0m total_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# 没有梯度了\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m test_dataloader: \u001b[38;5;66;03m# 测试数据集提取数据\u001b[39;00m\n\u001b[0;32m    103\u001b[0m         imgs, targets \u001b[38;5;241m=\u001b[39m data \u001b[38;5;66;03m# 数据放到cuda上\u001b[39;00m\n\u001b[0;32m    104\u001b[0m         imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device) \n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python3.12\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    171\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[1;32m--> 172\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "# 定义训练的设备\n",
    "#device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda\")   # 使用 GPU 方式一 \n",
    "#device = torch.device(\"cuda:0\") # 使用 GPU 方式二\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui, self).__init__()        \n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),  # 输入通道3，输出通道32，卷积核尺寸5×5，步长1，填充2    \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # 展平后变成 64*4*4 了\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(r'D:\\深度学习\\100_土堆数据集\\dataset', train=True, transform=torchvision.transforms.ToTensor())       \n",
    "# train=False: 下载并加载测试集 (10000张)\n",
    "test_data = torchvision.datasets.CIFAR10(r'D:\\深度学习\\100_土堆数据集\\dataset', train=False, transform=torchvision.transforms.ToTensor()) \n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10，则打印：训练数据集的长度为：10\n",
    "print(\"训练数据集的长度：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度：{}\".format(test_data_size))\n",
    "\n",
    "# 利用 Dataloader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)        \n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "tudui = Tudui() \n",
    "tudui = tudui.to(device) # 也可以不赋值，直接 tudui.to(device) \n",
    "\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵，fn 是 fuction 的缩写\n",
    "loss_fn = loss_fn.to(device) # 也可以不赋值，直接loss_fn.to(device)\n",
    "\n",
    "# 优化器\n",
    "learning = 0.01  # 1e-2 就是 0.01 的意思\n",
    "optimizer = torch.optim.SGD(tudui.parameters(),learning)   # 随机梯度下降优化器  \n",
    "\n",
    "# 设置网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "\n",
    "# 训练的轮次\n",
    "epoch = 10\n",
    "\n",
    "# 添加 tensorboard\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----第 {} 轮训练开始-----\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    tudui.train() # 当网络中有dropout层、batchnorm层时，这些层能起作用\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data            \n",
    "        imgs = imgs.to(device) \n",
    "        targets = targets.to(device) \n",
    "        outputs = tudui(imgs)\n",
    "        loss = loss_fn(outputs, targets) # 计算实际输出与目标输出的差距\n",
    "        \n",
    "        # 优化器对模型调优\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward() # 反向传播，计算损失函数的梯度\n",
    "        optimizer.step()   # 根据梯度，对网络的参数进行调优\n",
    "        \n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(end_time - start_time) # 运行训练一百次后的时间间隔\n",
    "            print(\"训练次数：{},Loss:{}\".format(total_train_step,loss.item()))  # 方式二：获得loss值\n",
    "    \n",
    "    # 测试步骤开始（每一轮训练后都查看在测试数据集上的loss情况）\n",
    "    tudui.eval()  # 当网络中有dropout层、batchnorm层时，这些层不能起作用\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():  # 没有梯度了\n",
    "        for data in test_dataloader: # 测试数据集提取数据\n",
    "            imgs, targets = data # 数据放到cuda上\n",
    "            imgs = imgs.to(device) \n",
    "            targets = targets.to(device) \n",
    "            outputs = tudui(imgs)\n",
    "            loss = loss_fn(outputs, targets) # 仅data数据在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss.item() # 所有loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "            \n",
    "    print(\"整体测试集上的Loss:{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率:{}\".format(total_accuracy/test_data_size))\n",
    "    total_test_step = total_test_step + 1\n",
    "    \n",
    "    torch.save(tudui, f\"D:\\\\深度学习\\\\Pytorch的使用\\\\model\\\\tudui_{i}.pth\") # 保存每一轮训练后的结果\n",
    "    #torch.save(tudui.state_dict(),\"tudui_{}.path\".format(i)) # 保存方式二         \n",
    "    print(\"模型已保存\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "350px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
