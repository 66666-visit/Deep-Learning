{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 实战Kaggle比赛狗的品种识别ImageNetDogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 比赛网址是 https://www.kaggle.com/c/dog-breed-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CPU dispatcher tracer already initlized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: CPU dispatcher tracer already initlized"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始整理训练集数据 (Copied)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10222it [00:25, 400.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始整理测试集数据...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10357/10357 [00:29<00:00, 350.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有数据整理完毕！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os  # [语法]: 导入标准库 os (Operating System)。 [作用]: 提供与操作系统交互的功能，比如路径拼接、创建文件夹、列出文件名。\n",
    "import shutil  # [语法]: 导入标准库 shutil (Shell Utilities)。 [作用]: 提供高级文件操作，最主要就是用来复制(copy)和移动文件。\n",
    "import pandas as pd  # [语法]: 导入 pandas 库并起别名 pd。 [作用]: 数据分析的神器，这里专门用来读取和处理 .csv 格式的标签文件。\n",
    "from tqdm import tqdm  # [语法]: 从 tqdm 库导入 tqdm 模块。 [作用]: 显示进度条。在处理成千上万张图片时，能让你知道代码跑到哪了，不至于干等。\n",
    "\n",
    "# 1. 定义路径 (根据你的实际存放位置修改)\n",
    "# [语法]: 变量赋值 (字符串)。\n",
    "# [作用]: 定义所有数据存放的根目录。所有的子文件夹都会在这个目录下。\n",
    "DATA_ROOT = './kaggle_dog'\n",
    "\n",
    "# [语法]: os.path.join 路径拼接。\n",
    "# [作用]: 拼接出原始训练集图片的存放路径 (例如 ./kaggle_dog/train)。它会自动适配 Windows(\\) 和 Linux(/) 的分隔符。\n",
    "ORIGIN_TRAIN_DIR = os.path.join(DATA_ROOT, 'train')\n",
    "\n",
    "# [语法]: os.path.join 路径拼接。\n",
    "# [作用]: 拼接出原始测试集图片的存放路径。\n",
    "ORIGIN_TEST_DIR = os.path.join(DATA_ROOT, 'test')\n",
    "\n",
    "# [语法]: os.path.join 路径拼接。\n",
    "# [作用]: 拼接出标签文件 labels.csv 的完整路径。\n",
    "LABEL_CSV = os.path.join(DATA_ROOT, 'labels.csv')\n",
    "\n",
    "# 目标路径: 我们把整理好的图片放到这里\n",
    "# [语法]: os.path.join 路径拼接。\n",
    "# [作用]: 定义一个新文件夹的路径，准备用来存放整理后(按品种分类)的训练图片。\n",
    "TARGET_TRAIN_DIR = os.path.join(DATA_ROOT, 'train_ready')\n",
    "\n",
    "# [语法]: os.path.join 路径拼接 (多层)。\n",
    "# [作用]: 定义整理后的测试集路径。\n",
    "# ★关键点★：为什么要加 'unknown'？因为 PyTorch 的 ImageFolder 读取数据时，强制要求格式为 root/类别名/图片。\n",
    "# 测试集没有类别，所以我们需要人为制造一个伪类别文件夹(unknown)，否则代码会报错。\n",
    "TARGET_TEST_DIR = os.path.join(DATA_ROOT, 'test_ready', 'unknown') \n",
    "\n",
    "# [语法]: 定义函数 organize_data。\n",
    "# [作用]: 封装数据整理的所有逻辑，方便一键调用。\n",
    "def organize_data():\n",
    "    \n",
    "    # [语法]: os.path.exists 判断路径是否存在。\n",
    "    # [作用]: 这是一个“防呆设计”。如果代码以前跑过，文件夹已经有了，就直接跳过，避免重复复制浪费时间。\n",
    "    if os.path.exists(TARGET_TRAIN_DIR):\n",
    "        \n",
    "        # [语法]: 打印提示信息。\n",
    "        # [作用]: 告诉用户程序为什么没有干活。\n",
    "        print(\"数据好像已经整理好了，跳过此步。\")\n",
    "        \n",
    "        # [语法]: return 语句。\n",
    "        # [作用]: 结束当前函数的执行，直接跳出。\n",
    "        return\n",
    "\n",
    "    # [语法]: 打印提示信息。\n",
    "    # [作用]: 提示用户程序开始处理训练集了。\n",
    "    print(\"开始整理训练集数据 (Copied)...\")\n",
    "    \n",
    "    # [语法]: pd.read_csv 读取 CSV 文件。\n",
    "    # [作用]: 将 labels.csv 读取为一个 DataFrame (表格对象)，方便后续查每一张图对应的品种。\n",
    "    df = pd.read_csv(LABEL_CSV)\n",
    "    \n",
    "    # [语法]: for 循环 + tqdm 进度条 + df.iterrows() 迭代器。\n",
    "    # [作用]: \n",
    "    # 1. df.iterrows(): 把表格一行一行地取出来。\n",
    "    # 2. tqdm(...): 给这个循环加个进度条，显示 \"处理到第几行了 / 总共多少行\"。\n",
    "    # 3. total=len(df): 告诉进度条总数，方便计算百分比。\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        \n",
    "        # [语法]: 字典/Series 取值。\n",
    "        # [作用]: 获取当前这一行里的 'id' 列的值 (即图片文件名，不含后缀)。\n",
    "        img_id = row['id']\n",
    "        \n",
    "        # [语法]: 字典/Series 取值。\n",
    "        # [作用]: 获取当前这一行里的 'breed' 列的值 (即狗的品种，也就是我们要创建的文件夹名)。\n",
    "        breed = row['breed']\n",
    "        \n",
    "        # [语法]: os.path.join + f-string 格式化字符串。\n",
    "        # [作用]: 拼凑出这张图片现在的完整路径。例如: ./kaggle_dog/train/001.jpg。\n",
    "        src = os.path.join(ORIGIN_TRAIN_DIR, f\"{img_id}.jpg\")\n",
    "        \n",
    "        # [语法]: os.path.join 路径拼接。\n",
    "        # [作用]: 拼凑出这张图片想去的地方。例如: ./kaggle_dog/train_ready/husky。\n",
    "        dst_dir = os.path.join(TARGET_TRAIN_DIR, breed)\n",
    "        \n",
    "        # [语法]: if 判断 + not 取反。\n",
    "        # [作用]: 检查目标品种文件夹是否存在。如果不存在(not exists)，才需要创建。\n",
    "        if not os.path.exists(dst_dir):\n",
    "            \n",
    "            # [语法]: os.makedirs 创建目录。\n",
    "            # [作用]: 创建对应的品种文件夹。makedirs 支持递归创建(如果上级目录也没有会一起创建)。\n",
    "            os.makedirs(dst_dir)\n",
    "            \n",
    "        # [语法]: shutil.copy 文件复制。\n",
    "        # [作用]: 核心动作！把图片从源路径(src) 复制到 目标文件夹下的同名文件。\n",
    "        # f\"{img_id}.jpg\" 是为了保持文件名不变。\n",
    "        shutil.copy(src, os.path.join(dst_dir, f\"{img_id}.jpg\"))\n",
    "\n",
    "    # [语法]: 打印提示信息。\n",
    "    # [作用]: 训练集搞定，提示开始搞测试集。\n",
    "    print(\"开始整理测试集数据...\")\n",
    "    \n",
    "    # [语法]: if 判断路径是否存在。\n",
    "    # [作用]: 检查测试集的目标文件夹 ./kaggle_dog/test_ready/unknown 是否存在。\n",
    "    if not os.path.exists(TARGET_TEST_DIR):\n",
    "        \n",
    "        # [语法]: os.makedirs 创建目录。\n",
    "        # [作用]: 如果不存在，就创建这个目录。\n",
    "        os.makedirs(TARGET_TEST_DIR)\n",
    "        \n",
    "    # [语法]: for 循环 + os.listdir 列出文件。\n",
    "    # [作用]: 遍历原始测试集文件夹(ORIGIN_TEST_DIR)下的所有文件名。\n",
    "    # tqdm 用来显示进度。\n",
    "    for img_name in tqdm(os.listdir(ORIGIN_TEST_DIR)):\n",
    "        \n",
    "        # [语法]: os.path.join 路径拼接。\n",
    "        # [作用]: 确定这张测试图现在的绝对路径。\n",
    "        src = os.path.join(ORIGIN_TEST_DIR, img_name)\n",
    "        \n",
    "        # [语法]: os.path.join 路径拼接。\n",
    "        # [作用]: 确定这张测试图要复制去的地方 (统一放到 unknown 文件夹下)。\n",
    "        dst = os.path.join(TARGET_TEST_DIR, img_name)\n",
    "        \n",
    "        # [语法]: shutil.copy 文件复制。\n",
    "        # [作用]: 执行复制操作。\n",
    "        shutil.copy(src, dst)\n",
    "        \n",
    "    # [语法]: 打印提示信息。\n",
    "    # [作用]: 告诉用户所有工作全部完成，可以进行下一步训练了。\n",
    "    print(\"所有数据整理完毕！\")\n",
    "\n",
    "# [语法]: 函数调用。\n",
    "# [作用]: 真正执行上面定义好的 organize_data 函数，开始干活。\n",
    "organize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms  \n",
    "# [语法]: 导入 torchvision.transforms 模块，并简写为 transforms。\n",
    "# [作用]: 这是一个图像处理工具箱，提供了裁剪、翻转、颜色调整、归一化等一系列功能。\n",
    "\n",
    "# ===========================\n",
    "# 1. 定义训练集预处理策略\n",
    "# ===========================\n",
    "# [语法]: 变量赋值。\n",
    "# [作用]: 训练集的数据增强策略。我们要故意把图片变得“难认”一点，强迫模型学到真正的特征，而不是死记硬背。\n",
    "train_transform = transforms.Compose([\n",
    "    \n",
    "    # [语法]: 随机缩放裁剪 (RandomResizedCrop)。\n",
    "    # 参数 224: 最终裁剪出的图片大小必须是 224x224 (这是 ResNet 模型的标准入口尺寸)。\n",
    "    # scale=(0.08, 1.0): 随机选取原图 8% 到 100% 的区域。\n",
    "    # ratio=(3.0/4.0, 4.0/3.0): 随机选取长宽比在 3/4 到 4/3 之间的区域。\n",
    "    # [作用]: \n",
    "    # 这是最强的增强手段！模拟物体可能出现在图片的任何位置、任何大小（比如狗有时候在角落，有时候占满全屏）。\n",
    "    # 它强迫模型去识别“狗的局部”也能认出是狗。\n",
    "    transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3.0/4.0, 4.0/3.0)),\n",
    "    \n",
    "    # [语法]: 随机水平翻转 (RandomHorizontalFlip)。默认概率 p=0.5。\n",
    "    # [作用]: \n",
    "    # 模拟“照镜子”。因为一只狗头朝左是狗，头朝右还是狗。\n",
    "    # 这能直接让训练数据量“翻倍”，防止模型只认识头朝左的狗。\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    \n",
    "    # [语法]: 颜色抖动 (ColorJitter)。\n",
    "    # brightness=0.4: 亮度随机变化 ±40%。\n",
    "    # contrast=0.4: 对比度随机变化 ±40%。\n",
    "    # saturation=0.4: 饱和度随机变化 ±40%。\n",
    "    # [作用]: \n",
    "    # 模拟不同的光照环境（比如白天、阴天、黄昏）。\n",
    "    # 防止模型根据背景颜色来作弊（比如误以为“草地上的都是狗，沙发上的都是猫”）。\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "    \n",
    "    # [语法]: 转为 Tensor (ToTensor)。\n",
    "    # [作用]: \n",
    "    # 1. 格式转换：把 PIL 图片 (整数 0-255, HxWxC) 变成 PyTorch Tensor (浮点数 0.0-1.0, CxHxW)。\n",
    "    # 2. 维度重排：PyTorch 卷积层要求“通道数”在前，这一步自动处理了。\n",
    "    # ★注意★：这一步必须在 Normalize 之前。\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # [语法]: 标准化 (Normalize)。\n",
    "    # 第一个列表是 RGB 三个通道的均值 (Mean)，第二个列表是标准差 (Std)。\n",
    "    # [作用]: \n",
    "    # 公式：result = (input - mean) / std。\n",
    "    # 为什么要用这几个奇怪的数字？因为这是 ImageNet 数据集百万张图片的统计结果。\n",
    "    # 既然我们要用 ImageNet 预训练好的 ResNet，就必须把我们的图片分布拉到和 ImageNet 一样，模型才能正常工作。\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ===========================\n",
    "# 2. 定义测试/验证集预处理策略\n",
    "# ===========================\n",
    "# [语法]: 变量赋值。\n",
    "# [作用]: 测试集不需要“花里胡哨”的随机变换，我们需要一个稳定、固定的输入，来公平地测试模型到底准不准。\n",
    "val_test_transform = transforms.Compose([\n",
    "    \n",
    "    # [语法]: 调整大小 (Resize)。\n",
    "    # 参数 256: 把图片短边缩放到 256 像素，长边按比例缩放。\n",
    "    # [作用]: \n",
    "    # 先把图变到 256 大小，比需要的 224 稍微大一点点，为下一步“中心裁剪”留出余地。\n",
    "    # (如果不先 Resize 直接 Crop，可能会切掉太多东西)。\n",
    "    transforms.Resize(256),\n",
    "    \n",
    "    # [语法]: 中心裁剪 (CenterCrop)。\n",
    "    # 参数 224: 从图片的正中心，切出一块 224x224 的区域。\n",
    "    # [作用]: \n",
    "    # 这是测试时的标准操作。我们默认物体大概率在图片中间。\n",
    "    # 不使用 RandomCrop，因为测试必须是可复现的（每次跑结果都得一样）。\n",
    "    transforms.CenterCrop(224),\n",
    "    \n",
    "    # [语法]: 转为 Tensor。\n",
    "    # [作用]: 同上，转成模型能读懂的 0-1 之间的浮点张量。\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # [语法]: 标准化。\n",
    "    # [作用]: 同上，使用和训练集完全一样的参数进行归一化。\n",
    "    # ★关键点★：测试集必须用和训练集一样的均值/标准差，千万不能重新算。\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: 9199 (使用增强变换)\n",
      "验证集: 1023 (使用普通变换)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "\n",
    "# 1. 准备两个“源”数据集 (Source Datasets)\n",
    "# 注意：这步很快，因为 ImageFolder 只读文件名，不读图片，所以内存开销很小。\n",
    "# Source A: 专门用于训练，带有数据增强 (train_transform) imagefolder会自动加标签并且从0开始，并且字典序从小到大\n",
    "train_source = ImageFolder(os.path.join(DATA_ROOT, 'train_ready'), transform=train_transform)\n",
    "\n",
    "# Source B: 专门用于验证，不带增强 (val_test_transform)\n",
    "val_source = ImageFolder(os.path.join(DATA_ROOT, 'train_ready'), transform=val_test_transform)\n",
    "\n",
    "# 2. 手动生成切分索引 (Indices)\n",
    "# 获取数据总数\n",
    "num_data = len(train_source)\n",
    "# 生成一个乱序的索引列表，比如 [3, 9, 1, 5, ...]\n",
    "indices = torch.randperm(num_data).tolist()  #生成全排列\n",
    "\n",
    "# 计算切分点 (90% 处)\n",
    "split_point = int(0.9 * num_data)\n",
    "\n",
    "# 切蛋糕：前 90% 给训练，后 10% 给验证\n",
    "train_indices = indices[:split_point]\n",
    "val_indices = indices[split_point:]\n",
    "\n",
    "# 3. 创建最终的 Dataset (Subset)\n",
    "# [语法]: Subset(源数据集, 索引列表)\n",
    "# [作用]: \n",
    "# train_ds 只会去 train_source 里取 train_indices 指定的那些图 (带增强)。\n",
    "# val_ds 只会去 val_source 里取 val_indices 指定的那些图 (不带增强)。\n",
    "train_ds = Subset(train_source, train_indices)\n",
    "val_ds = Subset(val_source, val_indices)\n",
    "\n",
    "# 4. 放入 DataLoader (和之前一样)\n",
    "train_iter = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_iter = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# 5. 测试集 (和之前一样)\n",
    "test_ds = ImageFolder(os.path.join(DATA_ROOT, 'test_ready'), transform=val_test_transform)\n",
    "test_iter = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"训练集: {len(train_ds)} (使用增强变换)\")\n",
    "print(f\"验证集: {len(val_ds)} (使用普通变换)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchvision\n",
    "class get_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = torchvision.models.resnet34(pretrained=True)\n",
    "        for param in self.features.parameters():\n",
    "        # [语法]: 设置 requires_grad = False\n",
    "        # [作用]: \n",
    "        # 告诉 PyTorch 的自动求导引擎：“在反向传播时，不要计算这些参数的梯度！”\n",
    "        # 结果就是：优化器（SGD/Adam）更新参数时，这部分的权重完全不会变。\n",
    "        # 既节省了显存，又加快了训练速度，还保留了大神的智慧。\n",
    "            param.requires_grad = False\n",
    "        self.output_new = nn.Sequential(\n",
    "            nn.Linear(1000, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 120)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.output_new(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [语法]: 定义函数 evaluate_loss\n",
    "# [参数]: \n",
    "# - data_iter: 数据加载器 (DataLoader)，里面装着验证集或测试集的数据。\n",
    "# - net: 训练好的模型。\n",
    "# - devices: 设备列表 (如 [cuda:0])。\n",
    "loss = nn.CrossEntropyLoss(reduction= 'none')\n",
    "def evaluate_loss(data_iter, net, devices):\n",
    "    \n",
    "    # [语法]: 多变量初始化\n",
    "    # [作用]: \n",
    "    # l_sum: 用来累加所有图片的“总扣分” (Total Loss)。\n",
    "    # n: 用来累加一共看了多少张图片 (Total Samples)。\n",
    "    l_sum, n = 0.0, 0\n",
    "    \n",
    "    # [语法]: 遍历 DataLoader\n",
    "    # [作用]: 一批一批地从数据集中取出图片 (features) 和标签 (labels)。\n",
    "    for features, labels in data_iter:\n",
    "        \n",
    "        # [语法]: Tensor.to(device)\n",
    "        # [作用]: 把数据搬运到 GPU 上 (devices[0])，因为模型在 GPU 上，数据也必须过去才能计算。\n",
    "        features, labels = features.to(devices), labels.to(devices)\n",
    "        \n",
    "        # [语法]: 模型前向传播 (Forward)\n",
    "        # [作用]: 让模型看图猜答案，得到预测结果 outputs。\n",
    "        outputs = net(features)\n",
    "        \n",
    "        # [语法]: 计算损失\n",
    "        # [作用]: 对比预测值 outputs 和真实值 labels。\n",
    "        # ★关键★: 因为上面设了 reduction='none'，这里返回的 l 是一个向量 (Vector)，\n",
    "        # 比如 batch_size=64，l 的形状就是 [64]，代表这 64 张图各自的 loss。\n",
    "        l = loss(outputs, labels)\n",
    "        \n",
    "        # [语法]: l.sum() 求和\n",
    "        # [作用]: 把这一个 batch 里所有图片的 loss 加起来，累加到总 loss (l_sum) 里。\n",
    "        l_sum += l.sum().item()\n",
    "        \n",
    "        # [语法]: labels.numel() 获取元素个数 (Number of Elements)\n",
    "        # [作用]: 统计这个 batch 里一共有多少张图 (比如 64 张)，累加到总数 n 里。\n",
    "        n += labels.shape[0]\n",
    "    \n",
    "    # [语法]: 除法运算\n",
    "    # [作用]: 总 Loss / 总图片数 = 平均 Loss。\n",
    "    # 这就是我们要的最终指标：平均每一张图猜错的程度。\n",
    "    return l_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # [语法]: 导入标准时间库。 [作用]: 用于记录训练耗时，计算每秒能处理多少张图片。\n",
    "import torch # [语法]: 导入 PyTorch 核心库。 [作用]: 深度学习的基础框架。\n",
    "from torch import nn # [语法]: 从 PyTorch 导入神经网络模块。 [作用]: 包含各种层（Linear, Conv2d）和容器（Sequential）。\n",
    "from cutmix and mixup 模版.utils_aug import cutmix_data, mixup_data, MixCriterion\n",
    "# [语法]: 定义训练函数 train。\n",
    "# [作用]: 封装整个训练流程，包括前向传播、反向传播、参数更新和验证。\n",
    "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay):\n",
    "    \n",
    "    # [语法]: 初始化 SGD (随机梯度下降) 优化器。\n",
    "    # [作用]: 它是“教”模型学习的老师。\n",
    "    # 1. [param for ... if ...]: 这是一个列表推导式。它只把那些 requires_grad=True (没被冻结) 的参数传给优化器。\n",
    "    #    (微调时，ResNet主体的参数被冻结了，不需要更新，所以不能传进去，否则报错或浪费资源)。\n",
    "    # 2. lr=lr: 学习率，决定每次参数更新的步子迈多大。\n",
    "    # 3. momentum=0.9: 动量。让优化器在下坡时有“惯性”，不容易卡在局部坑里，收敛更快。\n",
    "    # 4. weight_decay=wd: L2 正则化。惩罚过大的权重值，防止模型死记硬背 (过拟合)。\n",
    "    trainer = torch.optim.SGD(\n",
    "        [param for param in net.parameters() if param.requires_grad],\n",
    "        lr=lr, momentum=0.9, weight_decay=wd)\n",
    "    \n",
    "    # [语法]: 初始化学习率调度器 (Scheduler)。\n",
    "    # [作用]: 实现“学习率衰减”策略。\n",
    "    # StepLR: 每过 lr_period 个 Epoch，就把学习率乘以 lr_decay。\n",
    "    # 例如: 初始lr=0.01, period=10, decay=0.1 -> 第10轮时 lr 变成 0.001。\n",
    "    # 目的: 训练后期步子要迈小点，才能精细地找到最优解。\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n",
    "\n",
    "    # [语法]: for 循环 (Epoch Loop)。\n",
    "    # [作用]: 开始多轮训练。range(num_epochs) 生成从 0 到 num_epochs-1 的序列。\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # [语法]: 开启训练模式。\n",
    "        # [作用]: 这一步**至关重要**！\n",
    "        # 它会通知模型里的 Dropout 层开始随机丢弃神经元，通知 BatchNorm 层开始根据当前 Batch 更新均值和方差。\n",
    "        # 如果不写这句，模型可能无法正常训练。\n",
    "        net.train()\n",
    "        \n",
    "        # [语法]: 多变量赋值初始化。\n",
    "        # [作用]: 初始化本轮 (Epoch) 的统计指标。\n",
    "        # train_l_sum: 累加这一轮所有样本的总损失值。\n",
    "        # train_n: 累加这一轮一共训练了多少张图片。\n",
    "        train_l_sum, train_n = 0.0, 0\n",
    "        \n",
    "        # [语法]: time.time() 获取当前时间戳。\n",
    "        # [作用]: 记录这一轮开始的时间点，用于后面计算这一轮跑了多久。\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # [语法]: for 循环 + enumerate (Batch Loop)。\n",
    "        # [作用]: 从 DataLoader 中一批一批地取数据。\n",
    "        # i 是当前的批次索引 (0, 1, 2...)，(features, labels) 是图片和标签。\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            \n",
    "            # [语法]: Tensor.to(device) 数据迁移。\n",
    "            # [作用]: 把 CPU 上的图片和标签搬运到 GPU 上 (devices[0])，必须和模型在同一个设备上才能计算。\n",
    "            features, labels = features.to(devices), labels.to(devices)\n",
    "            \n",
    "            # [语法]: 优化器梯度清零。\n",
    "            # [作用]: 清空上一个 Batch 残留的梯度信息。\n",
    "            # PyTorch 默认会累加梯度，如果不清零，梯度的方向就全乱了，模型会学废。\n",
    "            trainer.zero_grad()\n",
    "            \n",
    "            # [语法]: 模型前向传播 (Forward Pass)。\n",
    "            # [作用]: 把图片喂给模型，计算出预测结果 output。\n",
    "            output = net(features)\n",
    "            \n",
    "            # [语法]: 计算损失 (Calculate Loss)。\n",
    "            # [作用]: \n",
    "            # 1. loss(output, labels): 调用之前定义的 CrossEntropyLoss (reduction='none')，算出一批 loss 向量。\n",
    "            # 2. .sum(): 把这个 Batch 里所有图片的 loss 加起来，变成一个标量 (Scalar)。\n",
    "            # *注意*: 这里加起来是为了后面方便做反向传播。\n",
    "            l = loss(output, labels).sum()\n",
    "            \n",
    "            # [语法]: 反向传播 (Backward Pass)。\n",
    "            # [作用]: 根据损失 l，利用链式法则自动计算出每个参数的梯度 (Gradients)。\n",
    "            l.backward()\n",
    "            \n",
    "            # [语法]: 参数更新 (Optimizer Step)。\n",
    "            # [作用]: 老师根据刚才算出的梯度，修正模型的参数权重。\n",
    "            trainer.step()\n",
    "            \n",
    "            # [语法]: 累加统计。\n",
    "            # [作用]: \n",
    "            # 1. l.item(): 把 Tensor 里的数值取出来变成 Python float。\n",
    "            # 2. labels.shape[0]: 获取当前 Batch 有多少张图 (比如 64 张)。\n",
    "            train_l_sum += l.item()\n",
    "            train_n += labels.shape[0]\n",
    "        \n",
    "        # [语法]: 调度器更新 (Scheduler Step)。\n",
    "        # [作用]: 这一轮 Epoch 跑完了，告诉调度器一声。\n",
    "        # 调度器会检查“现在是第几轮了？”，如果到了 lr_period 的倍数，它就会把学习率调小。\n",
    "        scheduler.step()\n",
    "        \n",
    "        # [语法]: if 判断语句。\n",
    "        # [作用]: 检查是否提供了验证集 (valid_iter)。如果是 None，说明不需要验证。\n",
    "        if valid_iter is not None:\n",
    "            \n",
    "            # [语法]: 调用自定义函数 evaluate_loss。\n",
    "            # [作用]: 让模型在验证集上跑一遍，看看它在没见过的题上能考多少分。\n",
    "            valid_loss = evaluate_loss(valid_iter, net, devices)\n",
    "        \n",
    "        # [语法]: 数学运算 (计算耗时)。\n",
    "        # [作用]: 当前时间 - 开始时间 = 这一轮花了几秒。\n",
    "        epoch_duration = time.time() - start_time\n",
    "        \n",
    "        # [语法]: 数学运算 (计算吞吐量)。\n",
    "        # [作用]: 这一轮处理的总图数 / 耗时 = 每秒能处理多少张图 (samples/sec)。\n",
    "        # 这是衡量显卡性能的重要指标。\n",
    "        throughput = train_n / epoch_duration\n",
    "        \n",
    "        # [语法]: f-string 字符串格式化。\n",
    "        # [作用]: 构造要打印的日志信息。\n",
    "        # :.3f 表示保留小数点后 3 位。\n",
    "        # train_l_sum / train_n = 平均训练损失。\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}: ')\n",
    "        print(f'Train Loss: {train_l_sum / train_n:.3f}')\n",
    "        \n",
    "        # [语法]: if 判断。\n",
    "        # [作用]: 如果有验证集，就把验证集损失拼接到日志字符串后面。\n",
    "        if valid_iter is not None:\n",
    "            print(f'Value Loss: {valid_loss}')\n",
    "        # [语法]: 打印输出。\n",
    "        # [作用]: 单独打印速度信息，方便监控硬件性能。\n",
    "        print(f'   Speed: {throughput:.1f} samples/sec on {str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: \n",
      "Train Loss: 2.585\n",
      "Value Loss: 0.994572864133475\n",
      "   Speed: 204.3 samples/sec on cuda\n",
      "Epoch 2/10: \n",
      "Train Loss: 1.431\n",
      "Value Loss: 0.8130415863305592\n",
      "   Speed: 215.8 samples/sec on cuda\n",
      "Epoch 3/10: \n",
      "Train Loss: 1.292\n",
      "Value Loss: 0.74445712927616\n",
      "   Speed: 209.9 samples/sec on cuda\n",
      "Epoch 4/10: \n",
      "Train Loss: 1.212\n",
      "Value Loss: 0.736484542503618\n",
      "   Speed: 180.2 samples/sec on cuda\n",
      "Epoch 5/10: \n",
      "Train Loss: 1.140\n",
      "Value Loss: 0.7128385840273322\n",
      "   Speed: 176.6 samples/sec on cuda\n",
      "Epoch 6/10: \n",
      "Train Loss: 1.108\n",
      "Value Loss: 0.7039528154091634\n",
      "   Speed: 190.8 samples/sec on cuda\n",
      "Epoch 7/10: \n",
      "Train Loss: 1.074\n",
      "Value Loss: 0.6832323568424288\n",
      "   Speed: 214.5 samples/sec on cuda\n",
      "Epoch 8/10: \n",
      "Train Loss: 1.039\n",
      "Value Loss: 0.6759233726434344\n",
      "   Speed: 198.5 samples/sec on cuda\n",
      "Epoch 9/10: \n",
      "Train Loss: 1.040\n",
      "Value Loss: 0.6713126733505831\n",
      "   Speed: 203.4 samples/sec on cuda\n",
      "Epoch 10/10: \n",
      "Train Loss: 1.031\n",
      "Value Loss: 0.6400620114651826\n",
      "   Speed: 212.8 samples/sec on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "# ===========================\n",
    "# 1. 自动检测硬件设备 (替换 d2l.try_all_gpus)\n",
    "# ===========================\n",
    "# [语法]: 定义 get_all_devices 函数\n",
    "# [作用]: 模仿 d2l 的功能。\n",
    "# 1. torch.cuda.device_count(): 检查有几张显卡。\n",
    "# 2. 列表推导式: 如果有卡，生成 [cuda:0, cuda:1...] 的列表。\n",
    "# 3. else: 如果没卡，返回 [cpu]。\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ===========================\n",
    "# 2. 设置超参数 (Hyperparameters)\n",
    "# ===========================\n",
    "# [语法]: 多变量赋值\n",
    "# [作用]: \n",
    "# num_epochs = 10: 训练 10 轮。\n",
    "# lr = 1e-4: 学习率 0.0001 (微调通常用很小的学习率，防止把预训练好的权重改坏了)。\n",
    "# wd = 1e-4: 权重衰减 (Weight Decay)，防止过拟合。\n",
    "num_epochs, lr, wd = 10, 1e-4, 1e-4\n",
    "\n",
    "# [语法]: 学习率衰减参数\n",
    "# [作用]: \n",
    "# lr_period = 2: 每隔 2 轮调整一次学习率。\n",
    "# lr_decay = 0.9: 每次调整为原来的 90% (即乘以 0.9)。\n",
    "lr_period, lr_decay = 2, 0.9\n",
    "\n",
    "# ===========================\n",
    "# 3. 初始化模型\n",
    "# ===========================\n",
    "# [语法]: 调用之前定义的 get_net 函数\n",
    "# [作用]: \n",
    "# 1. 下载 ResNet34。\n",
    "# 2. 冻结前层参数。\n",
    "# 3. 替换最后一层为 120 分类。\n",
    "# 4. 把模型搬到 GPU 上。\n",
    "net = get_net()\n",
    "net = net.to(device)\n",
    "\n",
    "# ===========================\n",
    "# 4. 开始训练\n",
    "# ===========================\n",
    "# [语法]: 调用训练函数\n",
    "# [作用]: \n",
    "# 把模型(net)、数据(iter)、超参全部传进去，开始跑代码。\n",
    "# 这一步会打印出每一轮的 Loss 和 速度。\n",
    "train(net, train_iter, val_iter, num_epochs, lr, wd,  device , lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "4992\n",
      "5056\n",
      "5120\n",
      "5184\n",
      "5248\n",
      "5312\n",
      "5376\n",
      "5440\n",
      "5504\n",
      "5568\n",
      "5632\n",
      "5696\n",
      "5760\n",
      "5824\n",
      "5888\n",
      "5952\n",
      "6016\n",
      "6080\n",
      "6144\n",
      "6208\n",
      "6272\n",
      "6336\n",
      "6400\n",
      "6464\n",
      "6528\n",
      "6592\n",
      "6656\n",
      "6720\n",
      "6784\n",
      "6848\n",
      "6912\n",
      "6976\n",
      "7040\n",
      "7104\n",
      "7168\n",
      "7232\n",
      "7296\n",
      "7360\n",
      "7424\n",
      "7488\n",
      "7552\n",
      "7616\n",
      "7680\n",
      "7744\n",
      "7808\n",
      "7872\n",
      "7936\n",
      "8000\n",
      "8064\n",
      "8128\n",
      "8192\n",
      "8256\n",
      "8320\n",
      "8384\n",
      "8448\n",
      "8512\n",
      "8576\n",
      "8640\n",
      "8704\n",
      "8768\n",
      "8832\n",
      "8896\n",
      "8960\n",
      "9024\n",
      "9088\n",
      "9152\n",
      "9216\n",
      "9280\n",
      "9344\n",
      "9408\n",
      "9472\n",
      "9536\n",
      "9600\n",
      "9664\n",
      "9728\n",
      "9792\n",
      "9856\n",
      "9920\n",
      "9984\n",
      "10048\n",
      "10112\n",
      "10176\n",
      "10240\n",
      "10304\n",
      "10357\n",
      "提交文件 submission.csv 生成完毕！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F # [语法]: 通常我们会把 functional 简写为 F\n",
    "\n",
    "# [语法]: 初始化列表\n",
    "# [作用]: 用来存放所有预测结果（概率值）。\n",
    "preds = []\n",
    "\n",
    "\n",
    "with torch.no_grad(): \n",
    "# [语法]: 遍历测试集 DataLoader\n",
    "# [作用]: 这里的 test_iter 应该是之前定义的DataLoader，batch_size=64。\n",
    "# 注意: test_iter 里虽然有 label，但在 Kaggle 测试集中 label 通常是占位符（或者空），我们不用它。\n",
    "    for data, label in test_iter:\n",
    "        \n",
    "        # [语法]: 模型推理 + Softmax 归一化\n",
    "        # [作用]: \n",
    "        # 1. net(data.to(...)): 把图片搬到 GPU 算出预测分数 (Logits)。此时形状是 [64, 120]。\n",
    "        # 2. F.softmax(..., dim=1): 核心！把分数变成概率 (0-1之间，和为1)。\n",
    "        # 必须改为 dim=1 (按行/类别归一化)。\n",
    "        # 含义：对于“每一张图”，它属于120个类别的概率之和应该是1。\n",
    "        data = data.to(device)\n",
    "        output = F.softmax(net(data), dim=1) \n",
    "        \n",
    "        #extend 和 append 的区别是 , append 是 直接 加到末尾 ， extend 是 把传入内容一个个拆掉，然后加入末尾\n",
    "        preds.extend(output.tolist())\n",
    "\n",
    "        # [语法]: 打印进度\n",
    "        # [作用]: 看着不断增加的数字 (64, 128, 192...)，知道程序在动。\n",
    "        print(len(preds))\n",
    "\n",
    "# [语法]: 获取文件名列表 (IDs)\n",
    "# [作用]: \n",
    "# 1. os.listdir(...): 读取测试集文件夹下的所有图片文件名 (如 '00a3edd22.jpg')。\n",
    "# 2. sorted(): ⚠️非常重要！ImageFolder 读取数据时是按文件名排序的。\n",
    "# 我们生成的 preds 列表也是按这个顺序排列的。\n",
    "# 所以这里获取文件名时，必须也 sort 一下，确保“文件名”和“预测结果”是一一对应的。\n",
    "# *注*: 这里的路径要改成你之前定义的 TARGET_TEST_DIR (比如 'kaggle_dog/test_ready/unknown')。\n",
    "ids = sorted(os.listdir(os.path.join(DATA_ROOT, 'test_ready', 'unknown')))    \n",
    "\n",
    "# [语法]: open 函数 + with 上下文管理器\n",
    "# [参数]: 'w' 表示 write (写入模式)。如果文件不存在会新建，如果存在会清空重写。\n",
    "# [作用]: \n",
    "# 1. 安全打开文件。\n",
    "# 2. 无论中间代码是否报错，with 语句结束时都会自动关闭文件 (f.close())，防止数据丢失。\n",
    "with open('submission.csv', 'w') as f:\n",
    "    \n",
    "    # ===========================\n",
    "    # 1. 写入表头 (Header)\n",
    "    # ===========================\n",
    "    # [语法]: 字符串拼接 ('id,' + ...) 和 join 方法。\n",
    "    # [作用]: \n",
    "    # Kaggle 规定第一行必须是列名。格式: id, breed1, breed2, ...\n",
    "    # train_source.classes: 这是一个列表 ['affenpinscher', 'beagle', ...]。\n",
    "    # ','.join(...): 把列表里的字符串用逗号连成一长串。\n",
    "    # '\\n': 换行符，写完表头必须换行，否则数据会接到表头后面。\n",
    "    f.write('id,' + ','.join(train_source.classes) + '\\n')\n",
    "    \n",
    "    # ===========================\n",
    "    # 2. 遍历数据 (Loop)\n",
    "    # ===========================\n",
    "    # [语法]: zip(列表A, 列表B) 打包函数。\n",
    "    # [作用]: \n",
    "    # ids 是文件名列表 ['001.jpg', '002.jpg']。\n",
    "    # preds 是预测概率列表 [[0.1, 0.9], [0.8, 0.2]]。\n",
    "    # zip 会把它们“拉链”一样一对一锁死，每次循环吐出一组 (i=文件名, output=概率向量)。\n",
    "    for i, output in zip(ids, preds):\n",
    "        \n",
    "        # ===========================\n",
    "        # 3. 写入每一行数据 (Data Row)\n",
    "        # ===========================\n",
    "        # 这行代码信息量很大，我们拆开看：\n",
    "        \n",
    "        # A. 处理 ID (文件名)\n",
    "        # [语法]: i.split('.')[0]\n",
    "        # [作用]: 把 '名字.jpg' 以 '.' 为界切开，取第 0 部分 ('001')。\n",
    "        # 为什么要切？因为 Kaggle 的提交格式要求 id 不能带 .jpg 后缀。\n",
    "        # split完是一个列表\n",
    "        image_id = i.split('.')[0]\n",
    "        \n",
    "        # B. 处理概率数值 (List Comprehension)\n",
    "        # [语法]: [str(num) for num in output]\n",
    "        # [作用]: output 本来是一堆浮点数 [0.01, 0.99]。\n",
    "        # join 方法只接受字符串列表，不接受数字。\n",
    "        # 所以必须用列表推导式，把每个 float 强转成 string。\n",
    "        str_probs = [str(num) for num in output]\n",
    "        \n",
    "        # C. 拼接成 CSV 格式\n",
    "        # [语法]: ','.join(...)\n",
    "        # [作用]: 把上面的字符串列表变成 \"0.01,0.99\"。\n",
    "        csv_probs = ','.join(str_probs)\n",
    "        \n",
    "        # D. 最终写入\n",
    "        # [作用]: 拼好 ID + 逗号 + 概率串 + 换行符。\n",
    "        # 结果样子: \"001,0.01,0.99\\n\"\n",
    "        f.write(image_id + ',' + csv_probs + '\\n')\n",
    "\n",
    "# [语法]: print 打印。\n",
    "# [作用]: 提示用户程序跑完了，可以去文件夹里找 submission.csv 文件并提交到 Kaggle 了。\n",
    "print(\"提交文件 submission.csv 生成完毕！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sdhsihd', 'shdskhd', 'sdhkahjd']\n"
     ]
    }
   ],
   "source": [
    "a = 'sdhsihd/shdskhd/sdhkahjd'\n",
    "print(a.split('/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "2041.23px",
    "left": "45.9792px",
    "top": "56px",
    "width": "465.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
